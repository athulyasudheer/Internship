# -*- coding: utf-8 -*-
"""internship_week_2.py.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jJfFXKt0OoM9ilS5Y90TvDWP55HNpgP-
"""

import numpy as np
import pandas as pd

score = pd.read_csv(r'/content/credit (3).csv') # calling data set

score

score.shape

score.columns

score.dtypes

score.describe()

score.info()

score.isna().sum() # No null values in the data set

# showing visualization of traget and feature variables
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8,6))
sns.countplot(x = 'Credit_Score', data = score, palette = 'Set3')
plt.title('Countplot of Credit Score')
plt.xlabel('Credit_Score')
plt.ylabel('Count')
plt.show()

plt.figure(figsize=(16,8))
sns.countplot(x = 'Occupation', data = score, palette = 'Set3')
plt.title('Countplot of Occupation')
plt.xlabel('Occupation')
plt.ylabel('Count')
plt.show()

top_10_age = score['Age'].value_counts().head(10).index.tolist()
data_top_10_age = score[score['Age'].isin(top_10_age)]
plt.figure(figsize=(10, 6))
sns.countplot(x = 'Age',data=data_top_10_age, palette='Set3')
plt.xticks(rotation=45)
plt.title('Top 10 Most Common Ages')
plt.xlabel('Age')
plt.ylabel('Count')
plt.show()

plt.figure(figsize=(8,6))
sns.histplot(x = 'Annual_Income', data = score, kde=True, color='salmon')
plt.title('Histogram of Annual Income')
plt.xlabel('Annual Income')
plt.ylabel('Frequency')
plt.show()

plt.figure(figsize = (16,10))
sns.barplot(x = 'Occupation', y = 'Annual_Income', data = score, palette = 'Set3')
plt.title('Occupation vs Annual_Income', fontweight = 'bold')
plt.show()

palette = 'colorblind'
plt.figure(figsize=(7,5))
score['Payment_of_Min_Amount'].value_counts().plot(kind='pie', autopct='%1.1f%%', colors=sns.color_palette(palette))
plt.title('Pie Chart of Payment of Minimum Amount')
plt.ylabel('')
plt.show()

plt.figure(figsize=(8,6))
sns.displot(score.Total_EMI_per_month ,kde = True, bins=30, color='g')
plt.title('Displot of Total_EMI_per_month')

plt.figure(figsize = (8,6))
sns.countplot(x = 'Credit_Score', hue = 'Payment_Behaviour', data = score, palette = 'Set3')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.title('Countplot of Credit_Score vs Payment_Behaviour')
plt.show()

plt.figure(figsize = (10,8))
sns.countplot(x = 'Credit_Score', hue = 'Occupation', data = score, palette = 'Set3')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.title('Countplot of Credit_Score vs Occupation')
plt.show()

sns.lineplot(x ='Credit_Score', y = 'Total_EMI_per_month', data = score)
plt.title('Lineplot of Credit Score V/S Total EMI per month')

plt.figure(figsize=(10, 6))
sns.histplot(score['Outstanding_Debt'], kde=True, color='salmon')
plt.title('Histogram of Outstanding_Debt')
plt.xlabel('Outstanding_Debt')
plt.ylabel('Frequency')
plt.show()

# Creating heat map for all numerial columns

plt.figure(figsize=(16,10))
sns.heatmap(data= score.corr(),annot = True)
plt.title('Correlation Heatmap')
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

score = pd.read_csv(r'/content/credit (3).csv') # Calling data set

score

score.columns

score.drop(['ID','Customer_ID','Month','Name','SSN','Num_Bank_Accounts','Num_Credit_Card','Interest_Rate','Num_of_Loan','Type_of_Loan','Delay_from_due_date','Num_of_Delayed_Payment','Changed_Credit_Limit','Num_Credit_Inquiries','Credit_Mix','Credit_Utilization_Ratio','Credit_History_Age'], axis=1,inplace=True)
# Droping columns

score.head(20)

score.columns

from sklearn.preprocessing import LabelEncoder
# using Label Encoding

label_encoder = LabelEncoder()

score['Payment_of_Min_Amount'] = label_encoder.fit_transform(score['Payment_of_Min_Amount'])
score['Occupation'] = label_encoder.fit_transform(score['Occupation'])
score['Payment_Behaviour'] = label_encoder.fit_transform(score['Payment_Behaviour'])

score.head(20)

# Seperating the data into features and labels
X = score[['Age', 'Occupation', 'Annual_Income', 'Monthly_Inhand_Salary','Outstanding_Debt', 'Payment_of_Min_Amount', 'Total_EMI_per_month','Amount_invested_monthly', 'Payment_Behaviour', 'Monthly_Balance']]
y = score['Credit_Score']

from sklearn.model_selection import train_test_split

##  Dividing the dataset into test and train data
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=42)

## Scaling the data
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

# Creat multiple Model for Evaluation

# 1) KNEIGHBORS CLASSIFIER

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

knn_classifier = KNeighborsClassifier()
knn_classifier.fit(X_train, y_train)

knn_predictions = knn_classifier.predict(X_test)
knn_accuracy = accuracy_score(y_test, knn_predictions)
print("K-Nearest Neighbors Classifier Accuracy:", knn_accuracy)

# Confusion matrix and classification report give more details about performance

from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

print(confusion_matrix(knn_predictions, y_test))
print(classification_report(knn_predictions, y_test))

# Creating Confusion Matrix Display

from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay
from sklearn.metrics import classification_report,accuracy_score,confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay

labels = ['Good', 'Poor', 'Standard']
result = confusion_matrix(y_test,knn_predictions)
result
cmd = ConfusionMatrixDisplay(result, display_labels = labels)
cmd.plot()

# 2)  SUPPORT VECTOR MEACHINES

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

##  Dividing the dataset into test and train data

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=42)

SVC_classifier = SVC()
SVC_classifier.fit(X_train, y_train)

SVC_predictions = SVC_classifier.predict(X_test)
SVC_accuracy = accuracy_score(y_test, SVC_predictions)
print("Support Vector Classifier Accuracy:", SVC_accuracy)

# Confusion matrix and classification report give more details about performance

from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

print(confusion_matrix(SVC_predictions, y_test))
print(classification_report(SVC_predictions, y_test))

# Creating Confusion Matrix Display

from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay
from sklearn.metrics import classification_report,accuracy_score,confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay

import matplotlib.pyplot as plt
import seaborn as sns

labels = ['Good', 'Poor', 'Standard']
result = confusion_matrix(y_test,SVC_predictions)
result
cmd = ConfusionMatrixDisplay(result, display_labels = labels)
cmd.plot()

#  3) DECISION TREE CLASSIFIER

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn import metrics

##  Dividing the dataset into test and train data
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=42)

from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier(criterion='entropy', max_depth=4)
clf = clf.fit(X_train,y_train)
clf = clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)

print('Accuracy:', metrics.accuracy_score(y_test,y_pred))

# Confusion matrix and classification report give more details about performance

from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

print(confusion_matrix(y_pred, y_test))
print(classification_report(y_pred, y_test))

# Creating Confusion Matrix Display

from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay
from sklearn.metrics import classification_report,accuracy_score,confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay

labels = ['Good', 'Poor', 'Standard']
result = confusion_matrix(y_test,y_pred)
result
cmd = ConfusionMatrixDisplay(result, display_labels = labels)
cmd.plot()

# 4) RANDOM FOREST CLASSIFIER

from sklearn.model_selection import train_test_split

##  Dividing the dataset into test and train data
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state =42)

from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(random_state=42)
rfc.fit(X_train, y_train)
y_pred_rfc = rfc.predict(X_test)
from sklearn.metrics import accuracy_score
print('Model accuracy score with 10 decision-tree : {0:0.4f}'. format(accuracy_score(y_test,y_pred_rfc)))

# Confusion matrix and classification report give more details about performance

from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

print(confusion_matrix(y_pred, y_test))
print(classification_report(y_pred, y_test))

# Creating Confusion Matrix Display

labels = ['Good', 'Poor', 'Standard']
result = confusion_matrix(y_test,y_pred)
result
cmd = ConfusionMatrixDisplay(result, display_labels = labels)
cmd.plot()

# Compair the four model with their accuracy score

Model_Comparison = pd.DataFrame({'Model':['K-Nearest Neighbors Classifier','Support Vector Classifier','Decision Tree Classifier','Random Forest Classifier'],'Accuracy_Score':[0.6461,0.5337,0.6101,0.7823]})

print(Model_Comparison)

# PLot the accuracy score of four models

plt.figure(figsize=(10, 5))
plt.bar(Model_Comparison['Model'], Model_Comparison['Accuracy_Score'])
plt.xlabel('Classification Model')
plt.ylabel('Accuracy_Score')
plt.title('Comparison of Accuracy_Score for Classification Models')
plt.xticks(rotation=45)
plt.show()

# For creating cross validation firstly creating LOGISTIC REGRESSION

from sklearn.model_selection import train_test_split

##  Dividing the dataset into test and train data
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state =42)

from sklearn.linear_model import LogisticRegression

LR_model = LogisticRegression()
LR_model = LR_model.fit(X_train, y_train)

# Finding LR_Score
score_LR = LR_model.score(X_test, y_test)
score_LR

# KFold Cross Validation

from sklearn.model_selection import KFold

Kfold_validator = KFold(10)
for train_index,test_index in Kfold_validator.split(X,y):
    print('Training Index:', train_index)
    print('Testing Index:', test_index)

from sklearn.model_selection import cross_val_score
cv_result = cross_val_score(LR_model,X,y,cv = Kfold_validator)

cv_result # Finding cv_result

# StratifiedKFold Cross Validation

from sklearn.model_selection import StratifiedKFold

# Creating traing index and testing index

skfold_validator = StratifiedKFold(n_splits = 10)
for train_index,test_index in skfold_validator.split(X,y):
    print('Training Index:', train_index)
    print('Testing Index:', test_index)

cv_result1 = cross_val_score(LR_model,X,y,cv = skfold_validator)

cv_result1 # Finding cv_result1

# Comparing both cv_result and cv_result1 using Mean()

np.mean(cv_result)

np.mean(cv_result1)

import pandas as pd
import numpy as np

# Compute mean cross-validation scores
cv_result = np.mean(cv_result)
cv_result1 = np.mean(cv_result1)

# Creating a DataFrame to store cross-validation scores and mean scores
cv_results = pd.DataFrame({'KFold Cross Validation':[0.5364,0.5447,0.5533, 0.5432, 0.5356,0.5502, 0.5538, 0.565,0.5482, 0.5506],'StratifiedKFold Corss Validation':[0.5461, 0.5436, 0.5522, 0.5472, 0.5442, 0.548 , 0.5518, 0.5542,0.5499, 0.5488]})

#  append mean scores to the DataFrame
cv_results.loc['Mean'] = [cv_result, cv_result1]

# DataFrame
print("Cross-validation scores:")
cv_results

# Stratified k-fold Cross Validation Scores

from matplotlib import pyplot as plt
cv_results['StratifiedKFold Corss Validation'].plot(kind='hist', bins=30, title='StratifiedKFold Corss Validation')
plt.gca().spines[['top', 'right',]].set_visible(False)

# k-fold Corss Validation Scores

from matplotlib import pyplot as plt
cv_results['KFold Cross Validation'].plot(kind='hist', bins=30, title='KFold Cross Validation')
plt.gca().spines[['top', 'right',]].set_visible(False)

# k-fold Cross Validation Scores vs Stratified k-fold Cross Validation Scores

from matplotlib import pyplot as plt
cv_results.plot(kind='scatter', x='KFold Cross Validation', y='StratifiedKFold Corss Validation')
plt.gca().spines[['top', 'right',]].set_visible(False)

#hyperparameter tuning
from sklearn.model_selection import GridSearchCV

#parameter grid for hyperparameter tuning
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10]
}

#GridSearchCV object with the random forest classifier and parameter grid
grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5)

# Performing GridSearchCV
grid_search.fit(X_train, y_train)

# Get the best hyperparameters
best_params = grid_search.best_params_
print("Best hyperparameters:", best_params)

# Get the best model
best_model = grid_search.best_estimator_

# Evaluate the best model on the test set
test_accuracy = best_model.score(X_test, y_test)
print("Test accuracy of the best model:", test_accuracy)

y_pred = best_model.predict(X_test)

#  accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

#  classification report
print("Classification Report:")
print(classification_report(y_test, y_pred))

#  confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(conf_matrix)

# Visualisation
import seaborn as sns
import matplotlib.pyplot as plt
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

